{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "atlantic-landing",
   "metadata": {
    "id": "infinite-cooper"
   },
   "source": [
    "#  Machine Translation Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spoken-killer",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "present-athletics",
    "outputId": "1be48cf0-94fa-4cea-90ca-ab411bc694a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import History \n",
    "callbacks_list = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-committee",
   "metadata": {
    "id": "6EF23SrD2KFO"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.1.0\n",
    "#!pip install keras==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extreme-amsterdam",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brief-recruitment",
    "outputId": "c7c69534-e613-4817-cf58-8114039b9b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kersa:  2.3.1 Tensorflow:  2.1.0\n"
     ]
    }
   ],
   "source": [
    "print('Kersa: ',keras.__version__,'Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alternate-enough",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "educated-auckland",
    "outputId": "17100e26-e154-4de3-b6b1-e85e472dc0db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Loading JW300_Data, Dropping ID column, removing all NaN\n",
    "JW300_data_load = pd.read_csv(\"yoruba_data.csv\")\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "JW300_data = JW300_data_load.drop(JW300_data_load.columns[0],axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fresh-reform",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "arbitrary-crisis",
    "outputId": "68163320-8d60-4dc3-ceb4-b02dc77f20e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307984</th>\n",
       "      <td>Judson pa dà sẹ́nu iṣẹ́ ìtumọ̀ tó ń ṣe tẹ́lẹ̀ láìka gbogbo ìbànújẹ́ tó dé bá a yìí sí .</td>\n",
       "      <td>Judson , though heartbroken , resumed his work .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297881</th>\n",
       "      <td>4 / 1</td>\n",
       "      <td>3 / 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38023</th>\n",
       "      <td>Èmi ni Jèhófà Ọlọ́run yín . ”</td>\n",
       "      <td>I am Jehovah your God . ”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472332</th>\n",
       "      <td>Àwọn Júù kan tiẹ̀ ń bú Jésù , wọ́n ń pè é ní ará Samáríà .</td>\n",
       "      <td>Many Judeans viewed the people of Galilee as inferior .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>Àmọ́ , ìṣòro kan wà o .</td>\n",
       "      <td>There was a problem , however .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Yoruba  \\\n",
       "307984  Judson pa dà sẹ́nu iṣẹ́ ìtumọ̀ tó ń ṣe tẹ́lẹ̀ láìka gbogbo ìbànújẹ́ tó dé bá a yìí sí .   \n",
       "297881  4 / 1                                                                                     \n",
       "38023   Èmi ni Jèhófà Ọlọ́run yín . ”                                                             \n",
       "472332  Àwọn Júù kan tiẹ̀ ń bú Jésù , wọ́n ń pè é ní ará Samáríà .                                \n",
       "47590   Àmọ́ , ìṣòro kan wà o .                                                                   \n",
       "\n",
       "                                                        English  \n",
       "307984  Judson , though heartbroken , resumed his work .         \n",
       "297881  3 / 15                                                   \n",
       "38023   I am Jehovah your God . ”                                \n",
       "472332  Many Judeans viewed the people of Galilee as inferior .  \n",
       "47590   There was a problem , however .                          "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JW300_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affected-vertex",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "direct-district",
    "outputId": "ffa7615e-7f06-4dfc-d897-03ea30f3c1ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Loading training data provided and dropping NaN\n",
    "language_train_dataset = pd.read_csv(\"Language_Train.csv\")\n",
    "language_train_dataset = language_train_dataset.drop(language_train_dataset.columns[0],axis = 1).dropna()\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solved-trout",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "matched-metallic",
    "outputId": "0e4939cb-95af-4e8b-8a7e-9aafe7ad1f8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>Ni báyìí o tí di aàyò ọkàn mi ju ti tẹ́lẹ̀ lọ, ju bí mo ti lérò lọ́kàn lọ pàápàá.</td>\n",
       "      <td>At this moment he has become irreplaceable in my heart than before, I never expected it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9263</th>\n",
       "      <td>Àdàbà ń pògèdè, ó rò pé ẹyẹlé ò gbọ́; ẹyẹlé gbọ́, títiiri ló tiiri.</td>\n",
       "      <td>The dove recites incantations, thinking that the pigeon cannot hear; the pigeon hears; it is only pretending to sleep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>Ọgbọ́n àgbọ́njù ní ń sọ ẹni diwin; bí oògún bá pọ̀ lápọ̀jù a sọni di wèrè; bóbìnrín bá gbọ́n àgbọ́njù, péńpé laṣọ ọkọọ ẹ̀ ń mọ.</td>\n",
       "      <td>Excessive cleverness turns one into a phantom; if there is too much magical charm it turns the owner into an imbecile; if a woman is too cunning her husband's clothes wind up ill-fitting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>Ní April 20, 1933, nínú ètò kan tí wọ́n ṣe lórí rédíò láti ṣayẹyẹ ọjọ́ ìbí Hitler, àlùfáà ṣọ́ọ̀ṣì Lutheran kan tó ń jẹ́ Otto sọ pé: “Ṣọ́ọ̀ṣì Lutheran ti ìpínlẹ̀ Saxony ti ronú gan-an nípa ìjọba tuntun tó gorí àlééfà yìí, a sì ti pinnu pé a máa fọwọ́ sowọ́ pọ̀ pẹ̀lú ìjọba tuntun yìí láti mú kí orílẹ̀-èdè wa di alágbára, kí ẹ̀sìn Kristẹni sì gbèrú.</td>\n",
       "      <td>On April 20, 1933, in a radio broadcast honoring Hitler’s birthday, Lutheran minister Otto said: “The German Lutheran Church of the State of Saxony has consciously come to terms with the new situation and will attempt in closest cooperation with the political leaders of our people once again to make available to the entire nation the strength of the ancient gospel of Jesus Christ.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>--- Ìdíje ò̩dó̩ nílè̩ Adúláwò̩: Kwara káwọn 26 lọ̀pàgó̩ fúngbàáradì.</td>\n",
       "      <td>--- Africa Youth Games: 26 Kwara athletes invited to camp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                            Yoruba  \\\n",
       "7438  Ni báyìí o tí di aàyò ọkàn mi ju ti tẹ́lẹ̀ lọ, ju bí mo ti lérò lọ́kàn lọ pàápàá.                                                                                                                                                                                                                                                                              \n",
       "9263  Àdàbà ń pògèdè, ó rò pé ẹyẹlé ò gbọ́; ẹyẹlé gbọ́, títiiri ló tiiri.                                                                                                                                                                                                                                                                                            \n",
       "5453  Ọgbọ́n àgbọ́njù ní ń sọ ẹni diwin; bí oògún bá pọ̀ lápọ̀jù a sọni di wèrè; bóbìnrín bá gbọ́n àgbọ́njù, péńpé laṣọ ọkọọ ẹ̀ ń mọ.                                                                                                                                                                                                                                \n",
       "2920  Ní April 20, 1933, nínú ètò kan tí wọ́n ṣe lórí rédíò láti ṣayẹyẹ ọjọ́ ìbí Hitler, àlùfáà ṣọ́ọ̀ṣì Lutheran kan tó ń jẹ́ Otto sọ pé: “Ṣọ́ọ̀ṣì Lutheran ti ìpínlẹ̀ Saxony ti ronú gan-an nípa ìjọba tuntun tó gorí àlééfà yìí, a sì ti pinnu pé a máa fọwọ́ sowọ́ pọ̀ pẹ̀lú ìjọba tuntun yìí láti mú kí orílẹ̀-èdè wa di alágbára, kí ẹ̀sìn Kristẹni sì gbèrú.   \n",
       "8322  --- Ìdíje ò̩dó̩ nílè̩ Adúláwò̩: Kwara káwọn 26 lọ̀pàgó̩ fúngbàáradì.                                                                                                                                                                                                                                                                                           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                              English  \n",
       "7438  At this moment he has become irreplaceable in my heart than before, I never expected it.                                                                                                                                                                                                                                                                                                         \n",
       "9263  The dove recites incantations, thinking that the pigeon cannot hear; the pigeon hears; it is only pretending to sleep.                                                                                                                                                                                                                                                                           \n",
       "5453  Excessive cleverness turns one into a phantom; if there is too much magical charm it turns the owner into an imbecile; if a woman is too cunning her husband's clothes wind up ill-fitting.                                                                                                                                                                                                      \n",
       "2920  On April 20, 1933, in a radio broadcast honoring Hitler’s birthday, Lutheran minister Otto said: “The German Lutheran Church of the State of Saxony has consciously come to terms with the new situation and will attempt in closest cooperation with the political leaders of our people once again to make available to the entire nation the strength of the ancient gospel of Jesus Christ.  \n",
       "8322  --- Africa Youth Games: 26 Kwara athletes invited to camp                                                                                                                                                                                                                                                                                                                                        "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_train_dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distant-knock",
   "metadata": {
    "id": "sunrise-situation"
   },
   "outputs": [],
   "source": [
    "data_frames = [language_train_dataset,JW300_data]\n",
    "dataset1 =pd.concat(data_frames).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relative-journalism",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "greek-quilt",
    "outputId": "3296320b-d056-42ab-9b7f-cb1adc743ecf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18875</th>\n",
       "      <td>Gbogbo wọn àyàfi Leghorn Funfun : © Barry Koffler / www.feathersite.com</td>\n",
       "      <td>All except White Leghorn : © Barry Koffler / www.feathersite.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20347</th>\n",
       "      <td>X ray : Lọ́lá àṣẹ Ìgbìmọ̀ Tó Ń Ṣèwádìí Nípa Àrùn Oríkèé - Ara - Ríro , Ilẹ̀ Gẹ̀ẹ́sì ( www.arc.org.uk )</td>\n",
       "      <td>X ray : Used by kind permission of the Arthritis Research Campaign , United Kingdom ( www.arc.org.uk )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23152</th>\n",
       "      <td>Ẹ̀YÌN ÌWÉ : UNITED NATIONS / RAY WITLIN</td>\n",
       "      <td>COVER : Map used with permission , © RMC , www.randmcnally.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23891</th>\n",
       "      <td>© Randolph Langenbach / UNESCO ( www.conservationtech.com )</td>\n",
       "      <td>© Randolph Langenbach / UNESCO ( www.conservationtech.com )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27206</th>\n",
       "      <td>Fọ́tò tó wà lókè : http : /⁠ /⁠ www.constabulary.com</td>\n",
       "      <td>Photograph above : http : / / www.constabulary.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466913</th>\n",
       "      <td>Àwa Ẹlẹ́rìí Jèhófà la ṣe é , o tún lè rí i lórí ìkànnì wa www.jw.org / yo</td>\n",
       "      <td>published by Jehovah’s Witnesses and available online at www.jw.org .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467232</th>\n",
       "      <td>Àwa Ẹlẹ́rìí Jèhófà la ṣe é , o tún lè wà á jáde lọ́fẹ̀ẹ́ lórí www.jw.org /⁠ yo</td>\n",
       "      <td>published by Jehovah’s Witnesses and available for free download at www.jw.org .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467263</th>\n",
       "      <td>Àwa Ẹlẹ́rìí Jèhófà la ṣe é jáde , o sì lè wà á jáde lọ́fẹ̀ẹ́ lórí ìkànnì www.jw.org / yo .</td>\n",
       "      <td>published by Jehovah’s Witnesses and available for free download at www.jw.org .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467321</th>\n",
       "      <td>Ó tún wà lórí www.jw.org / yo</td>\n",
       "      <td>Also available at www.jw.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470694</th>\n",
       "      <td>Ìkànnì www.jw.org , tv.jw.org , [ tá a ti máa ń wo Ètò Tẹlifíṣọ̀n JW ] àti wol.jw.org [ ìyẹn Àká Ìwé Orí Íńtánẹ́ẹ̀tì ] nìkan ni àwọn ìkànnì tí “ ẹrú ” náà ń lò láti gbé oúnjẹ tẹ̀mí jáde fún wa .</td>\n",
       "      <td>That “ slave ” uses only its official websites to publish spiritual food ​ — www.jw.org , tv.jw.org , and wol.jw.org .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    Yoruba  \\\n",
       "18875   Gbogbo wọn àyàfi Leghorn Funfun : © Barry Koffler / www.feathersite.com                                                                                                                              \n",
       "20347   X ray : Lọ́lá àṣẹ Ìgbìmọ̀ Tó Ń Ṣèwádìí Nípa Àrùn Oríkèé - Ara - Ríro , Ilẹ̀ Gẹ̀ẹ́sì ( www.arc.org.uk )                                                                                               \n",
       "23152   Ẹ̀YÌN ÌWÉ : UNITED NATIONS / RAY WITLIN                                                                                                                                                              \n",
       "23891   © Randolph Langenbach / UNESCO ( www.conservationtech.com )                                                                                                                                          \n",
       "27206   Fọ́tò tó wà lókè : http : /⁠ /⁠ www.constabulary.com                                                                                                                                                 \n",
       "...                                                      ...                                                                                                                                                 \n",
       "466913  Àwa Ẹlẹ́rìí Jèhófà la ṣe é , o tún lè rí i lórí ìkànnì wa www.jw.org / yo                                                                                                                            \n",
       "467232  Àwa Ẹlẹ́rìí Jèhófà la ṣe é , o tún lè wà á jáde lọ́fẹ̀ẹ́ lórí www.jw.org /⁠ yo                                                                                                                       \n",
       "467263  Àwa Ẹlẹ́rìí Jèhófà la ṣe é jáde , o sì lè wà á jáde lọ́fẹ̀ẹ́ lórí ìkànnì www.jw.org / yo .                                                                                                           \n",
       "467321  Ó tún wà lórí www.jw.org / yo                                                                                                                                                                        \n",
       "470694  Ìkànnì www.jw.org , tv.jw.org , [ tá a ti máa ń wo Ètò Tẹlifíṣọ̀n JW ] àti wol.jw.org [ ìyẹn Àká Ìwé Orí Íńtánẹ́ẹ̀tì ] nìkan ni àwọn ìkànnì tí “ ẹrú ” náà ń lò láti gbé oúnjẹ tẹ̀mí jáde fún wa .   \n",
       "\n",
       "                                                                                                                       English  \n",
       "18875   All except White Leghorn : © Barry Koffler / www.feathersite.com                                                        \n",
       "20347   X ray : Used by kind permission of the Arthritis Research Campaign , United Kingdom ( www.arc.org.uk )                  \n",
       "23152   COVER : Map used with permission , © RMC , www.randmcnally.com                                                          \n",
       "23891   © Randolph Langenbach / UNESCO ( www.conservationtech.com )                                                             \n",
       "27206   Photograph above : http : / / www.constabulary.com                                                                      \n",
       "...                                                    ...                                                                      \n",
       "466913  published by Jehovah’s Witnesses and available online at www.jw.org .                                                   \n",
       "467232  published by Jehovah’s Witnesses and available for free download at www.jw.org .                                        \n",
       "467263  published by Jehovah’s Witnesses and available for free download at www.jw.org .                                        \n",
       "467321  Also available at www.jw.org                                                                                            \n",
       "470694  That “ slave ” uses only its official websites to publish spiritual food ​ — www.jw.org , tv.jw.org , and wol.jw.org .  \n",
       "\n",
       "[152 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = dataset1[dataset1['English'].str.contains(\"www\")]\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lyric-monroe",
   "metadata": {
    "id": "smooth-mapping"
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset1, dataset2]).drop_duplicates(keep=False).convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hispanic-hands",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "surgical-employee",
    "outputId": "7e59580e-8061-4afd-bfaa-e8ad4a7f768a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A ṣètò Ìgbìmọ̀ Tó Ń Ṣètò Ìrànwọ́ Nígbà Àjálù láti wá bí àwọn ará wa níbẹ̀ ṣe máa rí àwọn nǹkan tí wọ́n máa nílò lọ́jọ́ iwájú.</td>\n",
       "      <td>A Disaster Relief Committee was formed to organize the long-term relief efforts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ìrọ̀lẹ́ May 22, 2018 ni wọ́n fàṣẹ ọba mú Arákùnrin Solovyev ní ibùdókọ̀ ojú irin nígbà tí òun àti Anna ìyàwó rẹ̀ ń bọ̀ láti ìrìn-àjò tí wọ́n lọ lórílẹ̀-èdè míì.</td>\n",
       "      <td>Brother Solovyev was arrested on the evening of May 22, 2018, at a railway station, as he was arriving home from a trip abroad with his wife, Anna.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iléeṣẹ́ Creative Commons náà</td>\n",
       "      <td>Creative Commons the Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pè̩lú Egypt, Morocco àti Tunisia tí wó̩n ti lo̩lé, Senegal nìkan lorílè̩èdè adúláwò̩ kan tó kù, wo̩n á fe̩sè̩wo̩nsè̩ pè̩lú Colombia ni ìfe̩sè̩wo̩nsè̩ tó ké̩yìn ikò̩ H ló̩jó̩bò̩.</td>\n",
       "      <td>With Egypt, Morocco and Tunisia out of the World Cup, Senegal, the only African nation left,  will take on Columbia in their last group H game on Thursday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adájọ́ àgbà lórílẹ̀ èdè Náíjíríà (Attorney General of the Federation), Justice Abubakar Malami ti pàsẹ fún ilé-isẹ́ ọ̀tẹlẹ̀múyẹ́ (Department of State Services, DSS) láti jáwọ́ lórí ẹ̀sun Omoyẹle Sowore ní kíákíá.</td>\n",
       "      <td>The Attorney General of the Federation, Justice Abubakar Malami has ordered the Department of State Services (DSS) to hands off the trial of Omoyele Sowore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474963</th>\n",
       "      <td>Lónìí , àwọn akéde tó lé ní ẹgbẹ̀rún lọ́nà àádọ́ta [ 50,000 ] ló ń wàásù ìhìn rere náà lórílẹ̀ - èdè Pọ́túgà àti láwọn erékùṣù míì tí wọ́n ti ń sọ èdè Potogí irú bí Azores àti Madeira .</td>\n",
       "      <td>Today , over 50,000 Kingdom publishers preach the good news of God’s Kingdom in Portugal and on several islands where Portuguese is spoken , including the Azores and Madeira .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474964</th>\n",
       "      <td>Ó dùn mọ́ni pé lára àwọn akéde tó wà ní Pọ́túgà lónìí ló jẹ́ ìran kẹta lára àwọn tó gbọ́ àsọyé mánigbàgbé tí Arákùnrin Rutherford sọ lọ́dún 1925 .</td>\n",
       "      <td>Among these publishers today are third - generation descendants of some of those who attended Brother Rutherford’s historic lecture in 1925 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474965</th>\n",
       "      <td>A dúpẹ́ lọ́wọ́ Jèhófà , a sì dúpẹ́ lọ́wọ́ àwọn arákùnrin àtàwọn arábìnrin tí wọ́n fìgboyà wàásù ìhìn rere náà .</td>\n",
       "      <td>We give thanks to Jehovah and to those early faithful brothers and sisters who courageously took the lead in spearheading the work as ‘ public servants of Christ Jesus to the nations . ’ ​ — Rom .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474966</th>\n",
       "      <td>Ṣe ni wọ́n fi hàn pé àwọn jẹ́ “ ìránṣẹ́ gbogbo ènìyàn fún Kristi Jésù sí àwọn orílẹ̀ - èdè . ” ​ — Róòmù 15 : 15 , 16 . ​ — Látinú Àpamọ́ Wa ní Pọ́túgà .</td>\n",
       "      <td>15 : 15 , 16 . ​ — From our archives in Portugal .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474967</th>\n",
       "      <td>Wo àpilẹ̀kọ náà , “ Ìkórè Ṣì Pọ̀ ” nínú Ilé Ìṣọ́ , May 15 , 2014 , ojú ìwé 31 àti 32 .</td>\n",
       "      <td>See “ There Is More Harvest Work to Be Done ” in The Watchtower , May 15 , 2014 , pp . 31 - 32 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435513 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                      Yoruba  \\\n",
       "0       A ṣètò Ìgbìmọ̀ Tó Ń Ṣètò Ìrànwọ́ Nígbà Àjálù láti wá bí àwọn ará wa níbẹ̀ ṣe máa rí àwọn nǹkan tí wọ́n máa nílò lọ́jọ́ iwájú.                                                                                          \n",
       "1       Ìrọ̀lẹ́ May 22, 2018 ni wọ́n fàṣẹ ọba mú Arákùnrin Solovyev ní ibùdókọ̀ ojú irin nígbà tí òun àti Anna ìyàwó rẹ̀ ń bọ̀ láti ìrìn-àjò tí wọ́n lọ lórílẹ̀-èdè míì.                                                       \n",
       "2       Iléeṣẹ́ Creative Commons náà                                                                                                                                                                                           \n",
       "3       Pè̩lú Egypt, Morocco àti Tunisia tí wó̩n ti lo̩lé, Senegal nìkan lorílè̩èdè adúláwò̩ kan tó kù, wo̩n á fe̩sè̩wo̩nsè̩ pè̩lú Colombia ni ìfe̩sè̩wo̩nsè̩ tó ké̩yìn ikò̩ H ló̩jó̩bò̩.                                      \n",
       "4       Adájọ́ àgbà lórílẹ̀ èdè Náíjíríà (Attorney General of the Federation), Justice Abubakar Malami ti pàsẹ fún ilé-isẹ́ ọ̀tẹlẹ̀múyẹ́ (Department of State Services, DSS) láti jáwọ́ lórí ẹ̀sun Omoyẹle Sowore ní kíákíá.   \n",
       "...                                                                                                                                                                                                                      ...   \n",
       "474963  Lónìí , àwọn akéde tó lé ní ẹgbẹ̀rún lọ́nà àádọ́ta [ 50,000 ] ló ń wàásù ìhìn rere náà lórílẹ̀ - èdè Pọ́túgà àti láwọn erékùṣù míì tí wọ́n ti ń sọ èdè Potogí irú bí Azores àti Madeira .                              \n",
       "474964  Ó dùn mọ́ni pé lára àwọn akéde tó wà ní Pọ́túgà lónìí ló jẹ́ ìran kẹta lára àwọn tó gbọ́ àsọyé mánigbàgbé tí Arákùnrin Rutherford sọ lọ́dún 1925 .                                                                     \n",
       "474965  A dúpẹ́ lọ́wọ́ Jèhófà , a sì dúpẹ́ lọ́wọ́ àwọn arákùnrin àtàwọn arábìnrin tí wọ́n fìgboyà wàásù ìhìn rere náà .                                                                                                        \n",
       "474966  Ṣe ni wọ́n fi hàn pé àwọn jẹ́ “ ìránṣẹ́ gbogbo ènìyàn fún Kristi Jésù sí àwọn orílẹ̀ - èdè . ” ​ — Róòmù 15 : 15 , 16 . ​ — Látinú Àpamọ́ Wa ní Pọ́túgà .                                                              \n",
       "474967  Wo àpilẹ̀kọ náà , “ Ìkórè Ṣì Pọ̀ ” nínú Ilé Ìṣọ́ , May 15 , 2014 , ojú ìwé 31 àti 32 .                                                                                                                                 \n",
       "\n",
       "                                                                                                                                                                                                     English  \n",
       "0       A Disaster Relief Committee was formed to organize the long-term relief efforts.                                                                                                                      \n",
       "1       Brother Solovyev was arrested on the evening of May 22, 2018, at a railway station, as he was arriving home from a trip abroad with his wife, Anna.                                                   \n",
       "2       Creative Commons the Organization                                                                                                                                                                     \n",
       "3       With Egypt, Morocco and Tunisia out of the World Cup, Senegal, the only African nation left,  will take on Columbia in their last group H game on Thursday.                                           \n",
       "4       The Attorney General of the Federation, Justice Abubakar Malami has ordered the Department of State Services (DSS) to hands off the trial of Omoyele Sowore.                                          \n",
       "...                                                                                                                                                              ...                                          \n",
       "474963  Today , over 50,000 Kingdom publishers preach the good news of God’s Kingdom in Portugal and on several islands where Portuguese is spoken , including the Azores and Madeira .                       \n",
       "474964  Among these publishers today are third - generation descendants of some of those who attended Brother Rutherford’s historic lecture in 1925 .                                                         \n",
       "474965  We give thanks to Jehovah and to those early faithful brothers and sisters who courageously took the lead in spearheading the work as ‘ public servants of Christ Jesus to the nations . ’ ​ — Rom .  \n",
       "474966  15 : 15 , 16 . ​ — From our archives in Portugal .                                                                                                                                                    \n",
       "474967  See “ There Is More Harvest Work to Be Done ” in The Watchtower , May 15 , 2014 , pp . 31 - 32 .                                                                                                      \n",
       "\n",
       "[435513 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reserved-plane",
   "metadata": {
    "id": "automated-norway"
   },
   "outputs": [],
   "source": [
    "#Fixing maximum scentence length as 20\n",
    "dataset =dataset[dataset['Yoruba'].apply(lambda x: len(x.split(' ')) < 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "premium-strip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "id": "superb-warehouse",
    "outputId": "386f9a24-7c13-4bbf-a0ec-751be12a1ee1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A ṣètò Ìgbìmọ̀ Tó Ń Ṣètò Ìrànwọ́ Nígbà Àjálù láti wá bí àwọn ará wa níbẹ̀ ṣe máa rí àwọn nǹkan tí wọ́n máa nílò lọ́jọ́ iwájú.</td>\n",
       "      <td>A Disaster Relief Committee was formed to organize the long-term relief efforts.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ìrọ̀lẹ́ May 22, 2018 ni wọ́n fàṣẹ ọba mú Arákùnrin Solovyev ní ibùdókọ̀ ojú irin nígbà tí òun àti Anna ìyàwó rẹ̀ ń bọ̀ láti ìrìn-àjò tí wọ́n lọ lórílẹ̀-èdè míì.</td>\n",
       "      <td>Brother Solovyev was arrested on the evening of May 22, 2018, at a railway station, as he was arriving home from a trip abroad with his wife, Anna.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iléeṣẹ́ Creative Commons náà</td>\n",
       "      <td>Creative Commons the Organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pè̩lú Egypt, Morocco àti Tunisia tí wó̩n ti lo̩lé, Senegal nìkan lorílè̩èdè adúláwò̩ kan tó kù, wo̩n á fe̩sè̩wo̩nsè̩ pè̩lú Colombia ni ìfe̩sè̩wo̩nsè̩ tó ké̩yìn ikò̩ H ló̩jó̩bò̩.</td>\n",
       "      <td>With Egypt, Morocco and Tunisia out of the World Cup, Senegal, the only African nation left,  will take on Columbia in their last group H game on Thursday.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adájọ́ àgbà lórílẹ̀ èdè Náíjíríà (Attorney General of the Federation), Justice Abubakar Malami ti pàsẹ fún ilé-isẹ́ ọ̀tẹlẹ̀múyẹ́ (Department of State Services, DSS) láti jáwọ́ lórí ẹ̀sun Omoyẹle Sowore ní kíákíá.</td>\n",
       "      <td>The Attorney General of the Federation, Justice Abubakar Malami has ordered the Department of State Services (DSS) to hands off the trial of Omoyele Sowore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474963</th>\n",
       "      <td>Lónìí , àwọn akéde tó lé ní ẹgbẹ̀rún lọ́nà àádọ́ta [ 50,000 ] ló ń wàásù ìhìn rere náà lórílẹ̀ - èdè Pọ́túgà àti láwọn erékùṣù míì tí wọ́n ti ń sọ èdè Potogí irú bí Azores àti Madeira .</td>\n",
       "      <td>Today , over 50,000 Kingdom publishers preach the good news of God’s Kingdom in Portugal and on several islands where Portuguese is spoken , including the Azores and Madeira .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474964</th>\n",
       "      <td>Ó dùn mọ́ni pé lára àwọn akéde tó wà ní Pọ́túgà lónìí ló jẹ́ ìran kẹta lára àwọn tó gbọ́ àsọyé mánigbàgbé tí Arákùnrin Rutherford sọ lọ́dún 1925 .</td>\n",
       "      <td>Among these publishers today are third - generation descendants of some of those who attended Brother Rutherford’s historic lecture in 1925 .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474965</th>\n",
       "      <td>A dúpẹ́ lọ́wọ́ Jèhófà , a sì dúpẹ́ lọ́wọ́ àwọn arákùnrin àtàwọn arábìnrin tí wọ́n fìgboyà wàásù ìhìn rere náà .</td>\n",
       "      <td>We give thanks to Jehovah and to those early faithful brothers and sisters who courageously took the lead in spearheading the work as ‘ public servants of Christ Jesus to the nations . ’ ​ — Rom .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474966</th>\n",
       "      <td>Ṣe ni wọ́n fi hàn pé àwọn jẹ́ “ ìránṣẹ́ gbogbo ènìyàn fún Kristi Jésù sí àwọn orílẹ̀ - èdè . ” ​ — Róòmù 15 : 15 , 16 . ​ — Látinú Àpamọ́ Wa ní Pọ́túgà .</td>\n",
       "      <td>15 : 15 , 16 . ​ — From our archives in Portugal .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474967</th>\n",
       "      <td>Wo àpilẹ̀kọ náà , “ Ìkórè Ṣì Pọ̀ ” nínú Ilé Ìṣọ́ , May 15 , 2014 , ojú ìwé 31 àti 32 .</td>\n",
       "      <td>See “ There Is More Harvest Work to Be Done ” in The Watchtower , May 15 , 2014 , pp . 31 - 32 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416639 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                      Yoruba  \\\n",
       "0       A ṣètò Ìgbìmọ̀ Tó Ń Ṣètò Ìrànwọ́ Nígbà Àjálù láti wá bí àwọn ará wa níbẹ̀ ṣe máa rí àwọn nǹkan tí wọ́n máa nílò lọ́jọ́ iwájú.                                                                                          \n",
       "1       Ìrọ̀lẹ́ May 22, 2018 ni wọ́n fàṣẹ ọba mú Arákùnrin Solovyev ní ibùdókọ̀ ojú irin nígbà tí òun àti Anna ìyàwó rẹ̀ ń bọ̀ láti ìrìn-àjò tí wọ́n lọ lórílẹ̀-èdè míì.                                                       \n",
       "2       Iléeṣẹ́ Creative Commons náà                                                                                                                                                                                           \n",
       "3       Pè̩lú Egypt, Morocco àti Tunisia tí wó̩n ti lo̩lé, Senegal nìkan lorílè̩èdè adúláwò̩ kan tó kù, wo̩n á fe̩sè̩wo̩nsè̩ pè̩lú Colombia ni ìfe̩sè̩wo̩nsè̩ tó ké̩yìn ikò̩ H ló̩jó̩bò̩.                                      \n",
       "4       Adájọ́ àgbà lórílẹ̀ èdè Náíjíríà (Attorney General of the Federation), Justice Abubakar Malami ti pàsẹ fún ilé-isẹ́ ọ̀tẹlẹ̀múyẹ́ (Department of State Services, DSS) láti jáwọ́ lórí ẹ̀sun Omoyẹle Sowore ní kíákíá.   \n",
       "...                                                                                                                                                                                                                      ...   \n",
       "474963  Lónìí , àwọn akéde tó lé ní ẹgbẹ̀rún lọ́nà àádọ́ta [ 50,000 ] ló ń wàásù ìhìn rere náà lórílẹ̀ - èdè Pọ́túgà àti láwọn erékùṣù míì tí wọ́n ti ń sọ èdè Potogí irú bí Azores àti Madeira .                              \n",
       "474964  Ó dùn mọ́ni pé lára àwọn akéde tó wà ní Pọ́túgà lónìí ló jẹ́ ìran kẹta lára àwọn tó gbọ́ àsọyé mánigbàgbé tí Arákùnrin Rutherford sọ lọ́dún 1925 .                                                                     \n",
       "474965  A dúpẹ́ lọ́wọ́ Jèhófà , a sì dúpẹ́ lọ́wọ́ àwọn arákùnrin àtàwọn arábìnrin tí wọ́n fìgboyà wàásù ìhìn rere náà .                                                                                                        \n",
       "474966  Ṣe ni wọ́n fi hàn pé àwọn jẹ́ “ ìránṣẹ́ gbogbo ènìyàn fún Kristi Jésù sí àwọn orílẹ̀ - èdè . ” ​ — Róòmù 15 : 15 , 16 . ​ — Látinú Àpamọ́ Wa ní Pọ́túgà .                                                              \n",
       "474967  Wo àpilẹ̀kọ náà , “ Ìkórè Ṣì Pọ̀ ” nínú Ilé Ìṣọ́ , May 15 , 2014 , ojú ìwé 31 àti 32 .                                                                                                                                 \n",
       "\n",
       "                                                                                                                                                                                                     English  \n",
       "0       A Disaster Relief Committee was formed to organize the long-term relief efforts.                                                                                                                      \n",
       "1       Brother Solovyev was arrested on the evening of May 22, 2018, at a railway station, as he was arriving home from a trip abroad with his wife, Anna.                                                   \n",
       "2       Creative Commons the Organization                                                                                                                                                                     \n",
       "3       With Egypt, Morocco and Tunisia out of the World Cup, Senegal, the only African nation left,  will take on Columbia in their last group H game on Thursday.                                           \n",
       "4       The Attorney General of the Federation, Justice Abubakar Malami has ordered the Department of State Services (DSS) to hands off the trial of Omoyele Sowore.                                          \n",
       "...                                                                                                                                                              ...                                          \n",
       "474963  Today , over 50,000 Kingdom publishers preach the good news of God’s Kingdom in Portugal and on several islands where Portuguese is spoken , including the Azores and Madeira .                       \n",
       "474964  Among these publishers today are third - generation descendants of some of those who attended Brother Rutherford’s historic lecture in 1925 .                                                         \n",
       "474965  We give thanks to Jehovah and to those early faithful brothers and sisters who courageously took the lead in spearheading the work as ‘ public servants of Christ Jesus to the nations . ’ ​ — Rom .  \n",
       "474966  15 : 15 , 16 . ​ — From our archives in Portugal .                                                                                                                                                    \n",
       "474967  See “ There Is More Harvest Work to Be Done ” in The Watchtower , May 15 , 2014 , pp . 31 - 32 .                                                                                                      \n",
       "\n",
       "[416639 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-compiler",
   "metadata": {},
   "source": [
    "# Selecting length of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "awful-tonight",
   "metadata": {
    "id": "looking-mining"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.head(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "turned-example",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "traditional-greene",
    "outputId": "b2e4c25d-51c0-4d51-b10f-efe8e7e7eb64"
   },
   "outputs": [],
   "source": [
    "dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "suburban-singing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "specified-schedule",
    "outputId": "f673e71f-1bc6-4770-c574-630cbc5d2957"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>erékùṣù náà ní ẹwà àdánidá</td>\n",
       "      <td>START_ the island also has natural beauty to offer _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13815</th>\n",
       "      <td>iṣẹ́ abẹ láìlo ẹ̀jẹ̀ ní gúúsù áfíríkà</td>\n",
       "      <td>START_ bloodless surgery in south africa _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10631</th>\n",
       "      <td>ti ìdílé rẹ lẹ́yìn</td>\n",
       "      <td>START_ support your family _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14682</th>\n",
       "      <td>nígbà tí wọ́n fẹ́ ti ọgbà ẹ̀wọ̀n kan tó wà ní ìlú cooma ní ọsirélíà pa àwọn èèyàn fárí gá</td>\n",
       "      <td>START_ when a prison in the small australian town of cooma was to be closed people protested _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12246</th>\n",
       "      <td>graph àwòrán tó wà ní ojú ìwé</td>\n",
       "      <td>START_ graph picture on page _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>ṣe ìwé ọkọ̀ náà ni orúkọ rẹ̀ kí o sì lo ìdánimọ̀ tìrẹ</td>\n",
       "      <td>START_ register the car in his name and use your biometrics _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>creative commons bẹ̀rẹ̀ láti wá wọ̀rọ̀kọ̀ fi ṣe àdá látàrí ètò ẹ̀tọ́ àti àṣẹ ẹ̀dà lórí iṣẹ́ ọpọlọ àtinúdá àgbáńlá ayé tí kò bá ìgbà mu</td>\n",
       "      <td>START_ creative commons began in response to an outdated global copyright legal system _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>láàárín ìlú ńlá mẹ́síkò gan an èèyàn lè ṣèbẹ̀wò sí tẹ́ńpìlì pàtàkì ti àwọn èèyàn aztec</td>\n",
       "      <td>START_ right in the heart of mexico city one can visit the main temple of the aztecs _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>iye owó tí ìwà ipá ń náni ń ròkè sí i</td>\n",
       "      <td>START_ the soaring cost of crime _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22199</th>\n",
       "      <td>àwọn mìíràn sọ pé ìjẹ́pàtàkì ilà yìí ni láti fi fa àwọn ẹlẹgbẹ́ rẹ̀ mọ́ra fún ìbálòpọ̀</td>\n",
       "      <td>START_ carried by the wind the distant sound of a lion’s roar reaches their ears and they tense they know the sound well _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       Yoruba  \\\n",
       "7159   erékùṣù náà ní ẹwà àdánidá                                                                                                               \n",
       "13815  iṣẹ́ abẹ láìlo ẹ̀jẹ̀ ní gúúsù áfíríkà                                                                                                    \n",
       "10631  ti ìdílé rẹ lẹ́yìn                                                                                                                       \n",
       "14682  nígbà tí wọ́n fẹ́ ti ọgbà ẹ̀wọ̀n kan tó wà ní ìlú cooma ní ọsirélíà pa àwọn èèyàn fárí gá                                                \n",
       "12246  graph àwòrán tó wà ní ojú ìwé                                                                                                            \n",
       "...                              ...                                                                                                            \n",
       "3829   ṣe ìwé ọkọ̀ náà ni orúkọ rẹ̀ kí o sì lo ìdánimọ̀ tìrẹ                                                                                    \n",
       "8596   creative commons bẹ̀rẹ̀ láti wá wọ̀rọ̀kọ̀ fi ṣe àdá látàrí ètò ẹ̀tọ́ àti àṣẹ ẹ̀dà lórí iṣẹ́ ọpọlọ àtinúdá àgbáńlá ayé tí kò bá ìgbà mu   \n",
       "8359   láàárín ìlú ńlá mẹ́síkò gan an èèyàn lè ṣèbẹ̀wò sí tẹ́ńpìlì pàtàkì ti àwọn èèyàn aztec                                                   \n",
       "18976  iye owó tí ìwà ipá ń náni ń ròkè sí i                                                                                                    \n",
       "22199  àwọn mìíràn sọ pé ìjẹ́pàtàkì ilà yìí ni láti fi fa àwọn ẹlẹgbẹ́ rẹ̀ mọ́ra fún ìbálòpọ̀                                                   \n",
       "\n",
       "                                                                                                                             English  \n",
       "7159   START_ the island also has natural beauty to offer _END                                                                        \n",
       "13815  START_ bloodless surgery in south africa _END                                                                                  \n",
       "10631  START_ support your family _END                                                                                                \n",
       "14682  START_ when a prison in the small australian town of cooma was to be closed people protested _END                              \n",
       "12246  START_ graph picture on page _END                                                                                              \n",
       "...                                  ...                                                                                              \n",
       "3829   START_ register the car in his name and use your biometrics _END                                                               \n",
       "8596   START_ creative commons began in response to an outdated global copyright legal system _END                                    \n",
       "8359   START_ right in the heart of mexico city one can visit the main temple of the aztecs _END                                      \n",
       "18976  START_ the soaring cost of crime _END                                                                                          \n",
       "22199  START_ carried by the wind the distant sound of a lion’s roar reaches their ears and they tense they know the sound well _END  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dynamic-cuisine",
   "metadata": {
    "id": "varying-psychiatry"
   },
   "outputs": [],
   "source": [
    "# convert Yoruba and English text to Lowercase \n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: x.lower())\n",
    "dataset.English=dataset.English.apply(lambda x: x.lower())\n",
    "# Remove quotes and hyphen from Yoruba and English text\n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: re.sub(\"-\", ' ', x))\n",
    "dataset.English=dataset.English.apply(lambda x: re.sub(\"-\", ' ', x))\n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: re.sub(\"'\", ' ', x))\n",
    "dataset.English=dataset.English.apply(lambda x: re.sub(\"'\", ' ', x))\n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: re.sub(\"—\", ' ', x))\n",
    "dataset.English=dataset.English.apply(lambda x: re.sub(\"—\", ' ', x))\n",
    "# create a set of all special characters\n",
    "special_characters= set(string.punctuation)\n",
    "# Remove all the special characters\n",
    "dataset.Yoruba = dataset.Yoruba.apply(lambda x: ''.join(char1 for char1 in x if char1 not in special_characters))\n",
    "dataset.English = dataset.English.apply(lambda x: ''.join(char1 for char1 in x if char1 not in special_characters))\n",
    "# Remove digits from Yoruba and English sentences\n",
    "num_digits= str.maketrans('','', digits)\n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: x.translate(num_digits))\n",
    "dataset.English= dataset.English.apply(lambda x: x.translate(num_digits))\n",
    "# Remove extra spaces\n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: x.strip())\n",
    "dataset.English=dataset.English.apply(lambda x: x.strip())\n",
    "dataset.Yoruba=dataset.Yoruba.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "dataset.English=dataset.English.apply(lambda x: re.sub(\" +\", \" \", x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "decreased-nothing",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "quiet-bottom",
    "outputId": "a45b3fe8-a97c-4a75-a621-33784da49197"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Yoruba</th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>erékùṣù náà ní ẹwà àdánidá</td>\n",
       "      <td>START_ start the island also has natural beauty to offer end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13815</th>\n",
       "      <td>iṣẹ́ abẹ láìlo ẹ̀jẹ̀ ní gúúsù áfíríkà</td>\n",
       "      <td>START_ start bloodless surgery in south africa end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10631</th>\n",
       "      <td>ti ìdílé rẹ lẹ́yìn</td>\n",
       "      <td>START_ start support your family end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14682</th>\n",
       "      <td>nígbà tí wọ́n fẹ́ ti ọgbà ẹ̀wọ̀n kan tó wà ní ìlú cooma ní ọsirélíà pa àwọn èèyàn fárí gá</td>\n",
       "      <td>START_ start when a prison in the small australian town of cooma was to be closed people protested end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12246</th>\n",
       "      <td>graph àwòrán tó wà ní ojú ìwé</td>\n",
       "      <td>START_ start graph picture on page end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>ṣe ìwé ọkọ̀ náà ni orúkọ rẹ̀ kí o sì lo ìdánimọ̀ tìrẹ</td>\n",
       "      <td>START_ start register the car in his name and use your biometrics end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>creative commons bẹ̀rẹ̀ láti wá wọ̀rọ̀kọ̀ fi ṣe àdá látàrí ètò ẹ̀tọ́ àti àṣẹ ẹ̀dà lórí iṣẹ́ ọpọlọ àtinúdá àgbáńlá ayé tí kò bá ìgbà mu</td>\n",
       "      <td>START_ start creative commons began in response to an outdated global copyright legal system end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>láàárín ìlú ńlá mẹ́síkò gan an èèyàn lè ṣèbẹ̀wò sí tẹ́ńpìlì pàtàkì ti àwọn èèyàn aztec</td>\n",
       "      <td>START_ start right in the heart of mexico city one can visit the main temple of the aztecs end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>iye owó tí ìwà ipá ń náni ń ròkè sí i</td>\n",
       "      <td>START_ start the soaring cost of crime end _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22199</th>\n",
       "      <td>àwọn mìíràn sọ pé ìjẹ́pàtàkì ilà yìí ni láti fi fa àwọn ẹlẹgbẹ́ rẹ̀ mọ́ra fún ìbálòpọ̀</td>\n",
       "      <td>START_ start carried by the wind the distant sound of a lion’s roar reaches their ears and they tense they know the sound well end _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                       Yoruba  \\\n",
       "7159   erékùṣù náà ní ẹwà àdánidá                                                                                                               \n",
       "13815  iṣẹ́ abẹ láìlo ẹ̀jẹ̀ ní gúúsù áfíríkà                                                                                                    \n",
       "10631  ti ìdílé rẹ lẹ́yìn                                                                                                                       \n",
       "14682  nígbà tí wọ́n fẹ́ ti ọgbà ẹ̀wọ̀n kan tó wà ní ìlú cooma ní ọsirélíà pa àwọn èèyàn fárí gá                                                \n",
       "12246  graph àwòrán tó wà ní ojú ìwé                                                                                                            \n",
       "...                              ...                                                                                                            \n",
       "3829   ṣe ìwé ọkọ̀ náà ni orúkọ rẹ̀ kí o sì lo ìdánimọ̀ tìrẹ                                                                                    \n",
       "8596   creative commons bẹ̀rẹ̀ láti wá wọ̀rọ̀kọ̀ fi ṣe àdá látàrí ètò ẹ̀tọ́ àti àṣẹ ẹ̀dà lórí iṣẹ́ ọpọlọ àtinúdá àgbáńlá ayé tí kò bá ìgbà mu   \n",
       "8359   láàárín ìlú ńlá mẹ́síkò gan an èèyàn lè ṣèbẹ̀wò sí tẹ́ńpìlì pàtàkì ti àwọn èèyàn aztec                                                   \n",
       "18976  iye owó tí ìwà ipá ń náni ń ròkè sí i                                                                                                    \n",
       "22199  àwọn mìíràn sọ pé ìjẹ́pàtàkì ilà yìí ni láti fi fa àwọn ẹlẹgbẹ́ rẹ̀ mọ́ra fún ìbálòpọ̀                                                   \n",
       "\n",
       "                                                                                                                                       English  \n",
       "7159   START_ start the island also has natural beauty to offer end _END                                                                        \n",
       "13815  START_ start bloodless surgery in south africa end _END                                                                                  \n",
       "10631  START_ start support your family end _END                                                                                                \n",
       "14682  START_ start when a prison in the small australian town of cooma was to be closed people protested end _END                              \n",
       "12246  START_ start graph picture on page end _END                                                                                              \n",
       "...                                            ...                                                                                              \n",
       "3829   START_ start register the car in his name and use your biometrics end _END                                                               \n",
       "8596   START_ start creative commons began in response to an outdated global copyright legal system end _END                                    \n",
       "8359   START_ start right in the heart of mexico city one can visit the main temple of the aztecs end _END                                      \n",
       "18976  START_ start the soaring cost of crime end _END                                                                                          \n",
       "22199  START_ start carried by the wind the distant sound of a lion’s roar reaches their ears and they tense they know the sound well end _END  \n",
       "\n",
       "[30000 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "dataset.English = dataset.English.apply(lambda x : 'START_ '+ x + ' _END')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "rapid-context",
   "metadata": {
    "id": "recent-shaft"
   },
   "outputs": [],
   "source": [
    "# Find all the source and target words and sort them\n",
    "# Vocabulary of Source language\n",
    "all_source_words=set()\n",
    "for Yoruba in dataset.Yoruba:\n",
    "    for word in Yoruba.split():\n",
    "        if word not in all_source_words:\n",
    "            all_source_words.add(word)\n",
    "# Vocabulary of Target \n",
    "all_target_words=set()\n",
    "for English in dataset.English:\n",
    "    for word in English.split():\n",
    "        if word not in all_target_words:\n",
    "            all_target_words.add(word)\n",
    "# sort all unique source and target words\n",
    "source_words= sorted(list(all_source_words))\n",
    "target_words=sorted(list(all_target_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "accepted-screw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "acquired-burner",
    "outputId": "ea076d93-b233-45be-d723-740c08a667a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'òjìlélẹ́gbọ̀kànléláàádọ́ta'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(source_words, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aquatic-eligibility",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "controlled-racing",
    "outputId": "1d722740-546b-44b2-8452-c8da7616f137"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'institutionalization'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(target_words, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "small-tobago",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neither-humidity",
    "outputId": "e5941757-f00d-4d5a-a09a-ab08c4a923d5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Max length of the source sentence 57\n",
      " Max length of the target sentence 75\n"
     ]
    }
   ],
   "source": [
    "#Find maximum sentence length in  the source and target data\n",
    "source_length_list=[]\n",
    "for l in dataset.Yoruba:\n",
    "    source_length_list.append(len(l.split()))\n",
    "max_source_length= max(source_length_list)\n",
    "print(\" Max length of the source sentence\",max_source_length)\n",
    "\n",
    "target_length_list=[]\n",
    "for l in dataset.English:\n",
    "    target_length_list.append(len(l.split()))\n",
    "max_target_length= max(target_length_list)\n",
    "print(\" Max length of the target sentence\",max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fresh-tragedy",
   "metadata": {
    "id": "hairy-conversion"
   },
   "outputs": [],
   "source": [
    "# creating a word to index(word2idx) for source and target\n",
    "source_word2idx= dict([(word, i+1) for i,word in enumerate(source_words)])\n",
    "target_word2idx=dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "revised-inspiration",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bridal-matrix",
    "outputId": "20cb71fa-405d-4ed9-e39d-d65690cb803b"
   },
   "outputs": [],
   "source": [
    "#creating a dictionary for index to word for source and target vocabulary\n",
    "source_idx2word= dict([(i, word) for word, i in  source_word2idx.items()])\n",
    "#print(source_idx2word)\n",
    "target_idx2word =dict([(i, word) for word, i in target_word2idx.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-recognition",
   "metadata": {
    "id": "cordless-mathematics"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "limited-appendix",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emotional-indicator",
    "outputId": "fc1387a4-4fee-41df-a108-87afe674c208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27000,), (3000,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train - Test Split\n",
    "X, y = dataset.Yoruba, dataset.English\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "happy-taste",
   "metadata": {
    "id": "loved-delight"
   },
   "outputs": [],
   "source": [
    "# Input tokens for encoder\n",
    "num_encoder_tokens=len(source_words)\n",
    "# Input tokens for decoder zero padded\n",
    "num_decoder_tokens=len(target_words) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "strange-circuit",
   "metadata": {
    "id": "talented-trash"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    \n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_source_length),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_target_length),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_target_length, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = source_word2idx[word] \n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_word2idx[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        #print(word)\n",
    "                        decoder_target_data[i, t - 1, target_word2idx[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "coastal-suicide",
   "metadata": {
    "id": "offshore-peter"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "#batch_size = 64\n",
    "#epochs = 10\n",
    "latent_dim=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "capital-equity",
   "metadata": {
    "id": "manufactured-ranking"
   },
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "furnished-opposition",
   "metadata": {
    "id": "waiting-beaver"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "strong-accreditation",
   "metadata": {
    "id": "difficult-economics"
   },
   "outputs": [],
   "source": [
    "# Define the model that takes encoder and decoder input \n",
    "# to output decoder_outputs\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dynamic-depression",
   "metadata": {
    "id": "phantom-locking"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics=['acc'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "possible-stack",
   "metadata": {
    "id": "dental-constitution"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train) # Total Training samples\n",
    "val_samples = len(X_test)    # Total validation or test samples\n",
    "batch_size = 10\n",
    "epochs = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "contained-member",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "impossible-tracy",
    "outputId": "156bc4aa-0cfc-4959-d622-c3c37b5c5440"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2700/2700 [==============================] - 658s 244ms/step - loss: 1.3521 - acc: 0.2479 - val_loss: 1.3592 - val_acc: 0.2801\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.28011, saving model to weights-improvement-01-0.28.h5\n",
      "Epoch 2/40\n",
      "2700/2700 [==============================] - 662s 245ms/step - loss: 1.2298 - acc: 0.2966 - val_loss: 1.3558 - val_acc: 0.3018\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.28011 to 0.30180, saving model to weights-improvement-02-0.30.h5\n",
      "Epoch 3/40\n",
      "2700/2700 [==============================] - 670s 248ms/step - loss: 1.1653 - acc: 0.3221 - val_loss: 1.3370 - val_acc: 0.3121\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30180 to 0.31209, saving model to weights-improvement-03-0.31.h5\n",
      "Epoch 4/40\n",
      "2700/2700 [==============================] - 668s 247ms/step - loss: 1.1268 - acc: 0.3430 - val_loss: 1.3368 - val_acc: 0.3172\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.31209 to 0.31717, saving model to weights-improvement-04-0.32.h5\n",
      "Epoch 5/40\n",
      "2700/2700 [==============================] - 663s 246ms/step - loss: 1.0978 - acc: 0.3616 - val_loss: 1.3822 - val_acc: 0.3189\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.31717 to 0.31893, saving model to weights-improvement-05-0.32.h5\n",
      "Epoch 6/40\n",
      "2700/2700 [==============================] - 664s 246ms/step - loss: 1.0784 - acc: 0.3767 - val_loss: 1.3934 - val_acc: 0.3176\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.31893\n",
      "Epoch 7/40\n",
      "2700/2700 [==============================] - 665s 246ms/step - loss: 1.0666 - acc: 0.3902 - val_loss: 1.3631 - val_acc: 0.3157\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.31893\n",
      "Epoch 8/40\n",
      "2700/2700 [==============================] - 667s 247ms/step - loss: 1.0503 - acc: 0.4008 - val_loss: 1.3849 - val_acc: 0.3104\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.31893\n",
      "Epoch 9/40\n",
      "2700/2700 [==============================] - 665s 246ms/step - loss: 1.0266 - acc: 0.4117 - val_loss: 1.4712 - val_acc: 0.3072\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.31893\n",
      "Epoch 10/40\n",
      "2700/2700 [==============================] - 684s 253ms/step - loss: 0.9940 - acc: 0.4229 - val_loss: 1.4581 - val_acc: 0.3034\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.31893\n",
      "Epoch 11/40\n",
      "2700/2700 [==============================] - 670s 248ms/step - loss: 0.9598 - acc: 0.4348 - val_loss: 1.5062 - val_acc: 0.2937\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.31893\n",
      "Epoch 12/40\n",
      "2700/2700 [==============================] - 657s 243ms/step - loss: 0.9175 - acc: 0.4489 - val_loss: 1.5153 - val_acc: 0.2969\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.31893\n",
      "Epoch 13/40\n",
      "2700/2700 [==============================] - 653s 242ms/step - loss: 0.8766 - acc: 0.4641 - val_loss: 1.5200 - val_acc: 0.2922\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.31893\n",
      "Epoch 14/40\n",
      "2700/2700 [==============================] - 646s 239ms/step - loss: 0.8446 - acc: 0.4744 - val_loss: 1.5607 - val_acc: 0.2853\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.31893\n",
      "Epoch 15/40\n",
      "2700/2700 [==============================] - 646s 239ms/step - loss: 0.8177 - acc: 0.4829 - val_loss: 1.5981 - val_acc: 0.2851\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.31893\n",
      "Epoch 16/40\n",
      "2700/2700 [==============================] - 646s 239ms/step - loss: 0.7922 - acc: 0.4926 - val_loss: 1.6326 - val_acc: 0.2803\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.31893\n",
      "Epoch 17/40\n",
      "2700/2700 [==============================] - 646s 239ms/step - loss: 0.7722 - acc: 0.4996 - val_loss: 1.6833 - val_acc: 0.2769\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.31893\n",
      "Epoch 18/40\n",
      "2700/2700 [==============================] - 654s 242ms/step - loss: 0.7535 - acc: 0.5059 - val_loss: 1.6844 - val_acc: 0.2784\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.31893\n",
      "Epoch 19/40\n",
      "2700/2700 [==============================] - 652s 242ms/step - loss: 0.7418 - acc: 0.5093 - val_loss: 1.7286 - val_acc: 0.2775\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.31893\n",
      "Epoch 20/40\n",
      "2700/2700 [==============================] - 653s 242ms/step - loss: 0.7156 - acc: 0.5177 - val_loss: 1.7002 - val_acc: 0.2722\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.31893\n",
      "Epoch 21/40\n",
      "2700/2700 [==============================] - 654s 242ms/step - loss: 0.6992 - acc: 0.5240 - val_loss: 1.7065 - val_acc: 0.2724\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.31893\n",
      "Epoch 22/40\n",
      "2700/2700 [==============================] - 652s 242ms/step - loss: 0.6762 - acc: 0.5326 - val_loss: 1.7792 - val_acc: 0.2700\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.31893\n",
      "Epoch 23/40\n",
      "2700/2700 [==============================] - 651s 241ms/step - loss: 0.6554 - acc: 0.5398 - val_loss: 1.7940 - val_acc: 0.2669\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.31893\n",
      "Epoch 24/40\n",
      "2700/2700 [==============================] - 652s 241ms/step - loss: 0.6244 - acc: 0.5565 - val_loss: 1.7505 - val_acc: 0.2711\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.31893\n",
      "Epoch 25/40\n",
      "2700/2700 [==============================] - 652s 242ms/step - loss: 0.6088 - acc: 0.5646 - val_loss: 1.7999 - val_acc: 0.2693\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.31893\n",
      "Epoch 26/40\n",
      "2700/2700 [==============================] - 658s 244ms/step - loss: 0.5966 - acc: 0.5722 - val_loss: 1.7979 - val_acc: 0.2657\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.31893\n",
      "Epoch 27/40\n",
      "2700/2700 [==============================] - 674s 250ms/step - loss: 0.5865 - acc: 0.5779 - val_loss: 1.7176 - val_acc: 0.2708\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.31893\n",
      "Epoch 28/40\n",
      "2700/2700 [==============================] - 665s 246ms/step - loss: 0.5720 - acc: 0.5873 - val_loss: 1.7778 - val_acc: 0.2651\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.31893\n",
      "Epoch 29/40\n",
      "2700/2700 [==============================] - 673s 249ms/step - loss: 0.5527 - acc: 0.5978 - val_loss: 1.7858 - val_acc: 0.2728\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.31893\n",
      "Epoch 30/40\n",
      "2700/2700 [==============================] - 668s 247ms/step - loss: 0.5320 - acc: 0.6093 - val_loss: 1.8170 - val_acc: 0.2686\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.31893\n",
      "Epoch 31/40\n",
      "2700/2700 [==============================] - 665s 246ms/step - loss: 0.5126 - acc: 0.6200 - val_loss: 1.7695 - val_acc: 0.2662\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.31893\n",
      "Epoch 32/40\n",
      "2700/2700 [==============================] - 664s 246ms/step - loss: 0.4918 - acc: 0.6304 - val_loss: 1.7478 - val_acc: 0.2718\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.31893\n",
      "Epoch 33/40\n",
      "2700/2700 [==============================] - 665s 246ms/step - loss: 0.4713 - acc: 0.6415 - val_loss: 1.8560 - val_acc: 0.2666\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.31893\n",
      "Epoch 34/40\n",
      "2700/2700 [==============================] - 658s 244ms/step - loss: 0.4506 - acc: 0.6520 - val_loss: 1.8549 - val_acc: 0.2669\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.31893\n",
      "Epoch 35/40\n",
      "2700/2700 [==============================] - 654s 242ms/step - loss: 0.4295 - acc: 0.6625 - val_loss: 1.9022 - val_acc: 0.2707\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.31893\n",
      "Epoch 36/40\n",
      "2700/2700 [==============================] - 655s 243ms/step - loss: 0.4112 - acc: 0.6722 - val_loss: 1.8820 - val_acc: 0.2707\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.31893\n",
      "Epoch 37/40\n",
      "2700/2700 [==============================] - 664s 246ms/step - loss: 0.3945 - acc: 0.6806 - val_loss: 1.9255 - val_acc: 0.2708\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.31893\n",
      "Epoch 38/40\n",
      "2700/2700 [==============================] - 667s 247ms/step - loss: 0.3806 - acc: 0.6871 - val_loss: 1.8957 - val_acc: 0.2671\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.31893\n",
      "Epoch 39/40\n",
      "2700/2700 [==============================] - 667s 247ms/step - loss: 0.3673 - acc: 0.6946 - val_loss: 1.9816 - val_acc: 0.2704\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.31893\n",
      "Epoch 40/40\n",
      "2700/2700 [==============================] - 663s 246ms/step - loss: 0.3562 - acc: 0.6999 - val_loss: 1.9477 - val_acc: 0.2691\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.31893\n"
     ]
    }
   ],
   "source": [
    "my_model = model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "surface-wilderness",
   "metadata": {
    "id": "blessed-compiler"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"nmt_weights_30epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "secondary-keyboard",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CQ0oWMAo__-G",
    "outputId": "ccf7dbc8-54f6-4523-d812-b7bd7c4d456e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.24791735,\n",
       "  0.29655626,\n",
       "  0.3220528,\n",
       "  0.34304994,\n",
       "  0.36160603,\n",
       "  0.37669504,\n",
       "  0.39021388,\n",
       "  0.4008428,\n",
       "  0.41170132,\n",
       "  0.42286807,\n",
       "  0.43484575,\n",
       "  0.44892523,\n",
       "  0.46414658,\n",
       "  0.4744445,\n",
       "  0.4828744,\n",
       "  0.4926303,\n",
       "  0.49959144,\n",
       "  0.50585127,\n",
       "  0.50926256,\n",
       "  0.5177193,\n",
       "  0.52404124,\n",
       "  0.5326035,\n",
       "  0.5397818,\n",
       "  0.5565237,\n",
       "  0.5645957,\n",
       "  0.57221675,\n",
       "  0.5778725,\n",
       "  0.5873016,\n",
       "  0.5978167,\n",
       "  0.60930616,\n",
       "  0.62000334,\n",
       "  0.6303964,\n",
       "  0.64147216,\n",
       "  0.6520162,\n",
       "  0.66249,\n",
       "  0.6721859,\n",
       "  0.6806489,\n",
       "  0.6871115,\n",
       "  0.6945918,\n",
       "  0.6998649],\n",
       " 'loss': [1.352126937618962,\n",
       "  1.229768478296421,\n",
       "  1.1653482453469877,\n",
       "  1.1268014917329505,\n",
       "  1.097837145725886,\n",
       "  1.078417932567773,\n",
       "  1.0665692814522318,\n",
       "  1.050287369357215,\n",
       "  1.0265886960316588,\n",
       "  0.9940219768992177,\n",
       "  0.9598113988615848,\n",
       "  0.917471768811897,\n",
       "  0.8766393972988482,\n",
       "  0.8446034585877701,\n",
       "  0.8176671956313981,\n",
       "  0.7922090362398713,\n",
       "  0.7722022276344123,\n",
       "  0.7534791389659599,\n",
       "  0.7417879841835411,\n",
       "  0.7155594096801899,\n",
       "  0.6992293012473318,\n",
       "  0.6762277183709321,\n",
       "  0.6554100617048917,\n",
       "  0.6244197919081759,\n",
       "  0.6087584682581602,\n",
       "  0.5966115942928526,\n",
       "  0.5864748293989235,\n",
       "  0.5720330887481019,\n",
       "  0.5526723828691024,\n",
       "  0.5319877885668366,\n",
       "  0.512572200651522,\n",
       "  0.4917527253760232,\n",
       "  0.47127125960257316,\n",
       "  0.4505546125548857,\n",
       "  0.42951264721375926,\n",
       "  0.4111635979899654,\n",
       "  0.39450090001578686,\n",
       "  0.3806073419197842,\n",
       "  0.3672746541102727,\n",
       "  0.35623417131602764],\n",
       " 'val_acc': [0.28011420369148254,\n",
       "  0.30180081725120544,\n",
       "  0.31208592653274536,\n",
       "  0.3171736001968384,\n",
       "  0.3189305067062378,\n",
       "  0.3176494240760803,\n",
       "  0.3156546354293823,\n",
       "  0.31042054295539856,\n",
       "  0.3071995973587036,\n",
       "  0.3033563792705536,\n",
       "  0.2937484085559845,\n",
       "  0.2968778610229492,\n",
       "  0.29222941398620605,\n",
       "  0.2852933704853058,\n",
       "  0.2850920557975769,\n",
       "  0.2802972197532654,\n",
       "  0.27687492966651917,\n",
       "  0.2783939242362976,\n",
       "  0.27746057510375977,\n",
       "  0.2721532881259918,\n",
       "  0.2723912000656128,\n",
       "  0.26999378204345703,\n",
       "  0.2669009268283844,\n",
       "  0.2710552215576172,\n",
       "  0.26926174759864807,\n",
       "  0.26574796438217163,\n",
       "  0.2708173096179962,\n",
       "  0.26508912444114685,\n",
       "  0.27275723218917847,\n",
       "  0.2685663104057312,\n",
       "  0.26620548963546753,\n",
       "  0.27178725600242615,\n",
       "  0.26662641763687134,\n",
       "  0.2668643295764923,\n",
       "  0.27070751786231995,\n",
       "  0.27074411511421204,\n",
       "  0.27083560824394226,\n",
       "  0.26708394289016724,\n",
       "  0.27037808299064636,\n",
       "  0.26907873153686523],\n",
       " 'val_loss': [1.3592160940170288,\n",
       "  1.3558015823364258,\n",
       "  1.3369885683059692,\n",
       "  1.3368403911590576,\n",
       "  1.3822320699691772,\n",
       "  1.3933520317077637,\n",
       "  1.3630995750427246,\n",
       "  1.384893536567688,\n",
       "  1.471192717552185,\n",
       "  1.45814049243927,\n",
       "  1.506243348121643,\n",
       "  1.515317440032959,\n",
       "  1.5200176239013672,\n",
       "  1.5606920719146729,\n",
       "  1.5981152057647705,\n",
       "  1.6326088905334473,\n",
       "  1.6833224296569824,\n",
       "  1.6844005584716797,\n",
       "  1.728613257408142,\n",
       "  1.7001569271087646,\n",
       "  1.7064614295959473,\n",
       "  1.7791831493377686,\n",
       "  1.7939790487289429,\n",
       "  1.7505289316177368,\n",
       "  1.7998535633087158,\n",
       "  1.7978726625442505,\n",
       "  1.7176473140716553,\n",
       "  1.7777949571609497,\n",
       "  1.785823941230774,\n",
       "  1.8170112371444702,\n",
       "  1.7695032358169556,\n",
       "  1.747828483581543,\n",
       "  1.8559887409210205,\n",
       "  1.8549162149429321,\n",
       "  1.9021682739257812,\n",
       "  1.8820022344589233,\n",
       "  1.9255050420761108,\n",
       "  1.8956692218780518,\n",
       "  1.9816349744796753,\n",
       "  1.9476633071899414]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "careful-picnic",
   "metadata": {
    "id": "approved-cocktail"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"nmt_weights_30epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "coastal-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "data = DataFrame(my_model.history)\n",
    "data = data.round(decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "together-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('History.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "modern-consideration",
   "metadata": {
    "id": "special-conversation"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"Context vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_state_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_state_input)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_state_input,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "assigned-mobility",
   "metadata": {
    "id": "compound-deposit"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of \n",
    "    #target sequence with the start character.\n",
    "    target_seq[0, 0] = target_word2idx['START_']\n",
    "# Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "# Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word =target_idx2word[sampled_token_index]\n",
    "        decoded_sentence += ' '+ sampled_word\n",
    "# Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_word == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "# Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "# Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "possible-temple",
   "metadata": {
    "id": "bottom-rouge"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "olive-content",
   "metadata": {
    "id": "polish-forge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Source sentence: mi ò sọ wí pé dípò kí mò ń sọ wí pé àti àrùn aids ikọ́ àwúgbẹ ibà ọ̀rẹ̀rẹ̀ ibà pọ́njúpọ́ntọ̀ oǹkà rẹ̀ tẹ̀síwájú\n",
      "Actual Target Translation:  start i m not saying instead of i m saying as well as aids tb malaria typhoid the list goes on end \n",
      "Predicted Target Translation:  start i m saying i am victim i least as an addi\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print(\"Input Source sentence:\", X_train[k:k+1].values[0])\n",
    "print(\"Actual Target Translation:\", y_train[k:k+1].values[0][6:-4])\n",
    "print(\"Predicted Target Translation:\", decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aging-collection",
   "metadata": {
    "id": "powerful-guidance"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Source sentence: ṣé àwọn òbí ẹ ń ṣàròyé pé o kì í gba tẹlòmíràn rò pé anìkànjọpọ́n ni ẹ́\n",
      "Actual Target Translation:  start do your parents complain that you are inconsiderate and self centered end \n",
      "Predicted Target Translation:  start take me back end \n"
     ]
    }
   ],
   "source": [
    "test_gen = generate_batch(X_test, y_test, batch_size = 1)\n",
    "k=10\n",
    "k+=1\n",
    "(input_seq, actual_output), _ = next(test_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input Source sentence:', X_test[k:k+1].values[0])\n",
    "print('Actual Target Translation:', y_test[k:k+1].values[0][6:-4])\n",
    "print('Predicted Target Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-equity",
   "metadata": {},
   "source": [
    "# BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "abroad-bumper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for the translation is : 0.43742343691381713\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [[ \"àwọn\", \"míì\", \"tiẹ\" ,\"tún\" ,\"gbẹ́mìí\" ,\"mì\" ,\"torí\", \"pé\" ,\"wọn\", \"ò\", \"rí \",\"ìtọ́jú\" ,\"tó\" ,\"yẹ\", \"gbà\"],\n",
    "             [\"some\", \"have\", \"also\", \"died\", \"because\", \"they\" ,\"could\", \"not\" ,\"obtain\" ,\"needed\", \"medical\", \"treatment\"]]\n",
    "candidate = [\"some\" ,\"have\", \"also\", \"died\" ,\"because\" ,\"they\", \"did\" ,\"not\", \"have\"]\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(\"BLEU score for the translation is :\" ,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "express-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for the translation is : 2.9251770022770788e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reference = [[ \"ṣé\" ,\"àwọn\", \"òbí\" ,\"ẹ\", \"ń\", \"ṣàròyé\",\"pé\", \"o\" ,\"kì\", \"í\" ,\"gba\", \"tẹlòmíràn\", \"rò\", \"pé\" ,\"anìkànjọpón\", \"ni\",\"ẹ́\"],\n",
    "             [ \"start\", \"do\" ,\"your\", \"parents\" ,\"complain\" ,\"that\" ,\"you\" ,\"are\", \"inconsiderate\", \"and\" ,\"self\", \"centered\" ,\"end\"]]\n",
    "candidate = [\"start\" ,\"take\", \"me\", \"back\", \"end\" ]\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(\"BLEU score for the translation is :\" ,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "binding-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score for the translation is : 1.7084231998347353e-78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EngrS\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [[\"mi\", \"ò\", \"sọ\" ,\"wí\" ,\"pé\" ,\"dípò\", \"kí\", \"mò\", \"ń\", \"sọ\" ,\"wí\", \"pé\" ,\"àti\" ,'àrùn' ,\"aids\", \"ikọ\" ,\"àwúgbẹ\" ,\"ibà\", \"ọ̀rẹ̀rẹ̀\" ,\"ibà\", \"pọ́njúpọ́ntọ̀\" ,\"oǹkà\", \"rẹ \",\"tẹ̀síwájú\" ],\n",
    "             [ \"i\", \"m\", \"not\", \"saying\" ,\"instead\" ,\"of\", \"i\", \"m\", \"saying\" ,\"as\", \"well\", \"as\" ,\"aids\", \"tb\", \"malaria\", \"typhoid\", \"the\", \"list\", \"goes\", \"on\"]]\n",
    "candidate = [\"i\", \"m\" ,\"saying\" ,\"i\", \"am\" ,\"victim\", \"i\", \"least\", \"as\" ,\"an\" ,\"addi\"]\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(\"BLEU score for the translation is :\" ,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-panic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-hungarian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NMT_FINAL-Copy2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
